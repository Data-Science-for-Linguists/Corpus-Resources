Katherine Kairis, kak275@pitt.edu, 11/6/2017
# Visitor's log: Comparing Native and Non-native Spoken English
https://github.com/Data-Science-for-Linguists/Native_and_Non-native_English


### Dan's Visit, 11/6/2017
#### Something you learned
  - VOICE and BNC are both nice datasets.
  - I agree that looking into whether the participants' speech changed when they were conversing with native speakers could be really interesting.
  - I've only parsed HTML with BeautifulSoup, not XML, so that was new.
  - Nice work with the data processing!

#### Something else that came to your mind.
  - Can you train a binary classifier for native vs non-native speakers? That could be interesting. You could feed in features that you mention like average utterance length, common words, bigrams, stop words, etc. Might give some insight into what is better at distinguishing between native and non-native speakers!


### Chris's Visit Nov 7 2017
#### Something I learned
  - You gain a lot of insight into your data by taking statistics and then analyzing it in the context of your data, finding new info and writing code to address issues your run into. That's a practice I need to get better at doing

#### Something that came to mind
  - Your ipynb files are beautifully annotated with analysis and code!


### Ben's Visit Nov 15, 2017  
#### Something I learned  
    - Very interesting project and I love how clearly annotated your code is - it's not often that I can follow along! I especially liked your use of initial starter functions to quickly collect the info you wanted - this is something I need to do more of in order to boost efficiency. The comparison of stop word usage is also interesting, especially the spoken fillers by native speakers like 'yeah'. I think I read somewhere that 'I think' and 'yeah so' are the two most common bigrams in the spoken BNC.

#### Something that came to mind  
    -  Related to the above, it would be interesting to somehow separate at all the typically spoken fillers like 'yeah', 'oh', 'er', etc. and compare between the two groups.

### Alicia's Visit Nov 15, 2017
#### Something I learned
	- We both are extracting speaker information and texts for our projects, but the original formats of our data are very different. That said, your methods are succint and clear. I often end up using for loops, so looking at your project's code is very beneficial for me to see other methods of extracting speaker information and text.	
	
#### Something that came to mind
	- project_plan.md: I would recommend updating your project plan so that it is more definitive. This will make you sound more confident to anyone who reads about your project.
	- LICENSE.md: You have information about what you would like to do for your license, but your LICENSE.md is still empty. It sounds like you know what you want to do so you could formally write up your license.
	- Your use of markdown cells for headings and information is very helpful and makes the code more organized!

** Andrew's Visit Nov 20th **
I noticed when looking through the exploring_VOICE file that an overwhelming number of speakers in your dataset are English speakers (American and Great Britain). How do you plan to factor that in when doing analysis between native and non-native English speakers?

I think the analysis your doing on stop words is interesting. Have you considered expanding it to look at other lexical items?