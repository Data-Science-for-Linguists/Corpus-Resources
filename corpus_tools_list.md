# A list of corpora and corpus-related tools

- Let's collaborate on building this document.
- For "Access", indicate if the corpus is searchable online, needs purchasing, or freely downloadable.
- Don't worry about putting resources in alphabetical order! Just add whatever you like, and make sure you are not adding entries that someone else has already listed.

## Corpora mentioned in Gries & Newman

| Name/link | Access | Summary |
| --------- | :-----------: | ------- |
|[The British National Corpus](http://www.natcorp.ox.ac.uk/) | online or purchase | 100 million word collection of samples of written and spoken language from multiple sources, designed to represent a wide cross-section of British English from the late 20th century |
|[BNC Baby](http://www.natcorp.ox.ac.uk/corpus/babyinfo.html) | purchase | "Baby" version of the BNC. Contains BNC sampler and Brown corpus. |
|[TIMIT Acoustic-Phonetic Continuous Speech Corpus](https://catalog.ldc.upenn.edu/ldc93s1)|purchase| Audio recordings of 630 American English speakers of 8 different dialects reading phonetically rich sentences. |
|[International Corpus of English (ICE)](http://www.ucl.ac.uk/english-usage/projects/ice.htm) | mostly freely downloadable | One million-word corpora of a number of national or regional varieties of English. Grammatically analyzed and annotated.|
|[The Corpus of Historical American English (COHA)](https://corpus.byu.edu/coha/)| Free, but after 15-20 searches, registration required | The largest corpus of historical English, containing more than 400 million words of text of American English from 1810-2009. In particular, you can search language change through genres and time, such as from informal to more formal speech and writing. |
|[The Corpus of Contemporary American English (COCA)](https://corpus.byu.edu/coca/)| free online | A very large and well balanced corpus of American English. It contains 520 million words and is divided equally into spoken words, fiction, magazines, newspapers, and academic texts.||
|[Freiburg Brown corpus (FROWN) ](http://www.helsinki.fi/varieng/CoRD/corpora/FROWN/)| free online | Similar in composition and size to the Brown Corpus, except it represents the language of the 1990s.Like the original Brown and LOB corpora, Frown contains 500 texts of around 2000 words each, distributed across 15 text categories, 9 informative and 6 imaginative.||
|[The Brown Corpus](http://www.helsinki.fi/varieng/CoRD/corpora/BROWN/) | Available online | An American English corpus over 1 million words large. Divided into 15 categories. Limited to texts printed in 1961 |
|[The Michigan Corpus of Academic Spoken English](https://quod.lib.umich.edu/cgi/c/corpus/corpus?page=home;c=micase;cc=micase)|Available Online|A corpus of academic spoken English as recorded at the University of Michigan. The corpus was collected between 1997 and 2002. It contains ~200 hours of recordings, and approximately 1.8 million words.||
|[The Buckeye Corpus of Conversational Speech](http://buckeyecorpus.osu.edu)| The corpus is free for non-commercial use, but a license agreement needs to be filled out and submitted as well as other pieces of information for registration.| A corpus of speech recordings of 40 speakers in Columbus OH conversing freely with the interviewer. The audio and text files are stored in a format that is used with speech analysis software.|
|[Lancaster-Oslo-Bergen Corpus (LOB)](http://clu.uni.no/icame/manuals/LOB/INDEX.HTM)|The corpus is not free.  It is part of the International Computer Archive of Modern English (ICAME) and researchers are able to by access to the corpus through ICAME.|The link to the corpus given in Greis & Newman is now dead, the above link is to the corpus manual.  LOB is intended to be a British English conterpart to the Brown Corpus.  It contains 500  printed texts (about 1 million words).|
|[TalkBank](http://talkbank.org)|Available Online (some sections require membership)|A multi-lingual corpus with sub-corpora focusing on the following: child language, second language acquisition, aphasia, dementia, conversation analysis, and sociolinguistics|
|[Project Gutenberg](http://gutenberg.org)|Available Online| Freely available collection of over 54,000 books, especially English literature in the public domain.|
|[The Uppsala Student English Corpus (USE)](http://ota.ox.ac.uk/desc/2457)|Free under Creative Commons license (see site for details)|The USE contains approximately 1500 essays written by 440 Swedish university students of English, many were in their first full-term of study at the time. There are over 1.2 million words in the corpus, and the essays have an average length of 820 words.|
|[TIMIT Acoustic-Phonetic Continuous Speech Corpus](https://catalog.ldc.upenn.edu/ldc93s1)|Available for Members of LDC.|The TIMIT contains broadband recordings of 630 speakers of 8 major dialects of American English, each reading ten phonetically rich sentences. The corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.|

## Additional corpora

| Name/link | Access | Summary |
| --------- | :-----------: | ------- |
|[Tagged and Cleaned Wikipedia and its Ngram](http://nlp.cs.nyu.edu/wikipedia-data/) | freely downloadable | A static version (html documents) of the English Wikipedia, downloaded in 2008. Tagged and cleaned, includes n-grams. |
|[The Full Reddit Submission Corpus](https://www.reddit.com/r/datasets/comments/3mg812/full_reddit_submission_corpus_now_available_2006/) | freely downloadable | All publicly available Reddit submissions from January 2006 - August 31, 2015 - over 1.7 billion comments. JSON objects tagged with comment, score, author, and other fields|
|[Most Popular Baby Names by Sex and Mother's Ethnic Group, New York City](https://catalog.data.gov/dataset/most-popular-baby-names-by-sex-and-mothers-ethnic-group-new-york-city-8c742)| freely downloadable | Most popular baby names organized by the race of the mother in NYC from 2013. |
|[Yelp Dataset Challenge](https://www.yelp.com/dataset/challenge) | freely downloadable | Opportunity for students to conduct research and analysis of yelp review data. You can win one of ten awards for $5000. Reviews are categorized in business, reviews, user, check in, and tip. |
|[Cornell NLVR](http://lic.nlp.cornell.edu/nlvr/)| freely downloadable | Cornell Natural Language Visual Reasoning dataset of natural language statements grounded in synthetic images. |
|[Ubuntu Chat Corpus (UCC)](http://daviduthus.org/UCC/)| freely downloadable | A corpus composed of chat logs from Ubuntu's Internet Relay Chat technical support channels. The chats are labelled HAQ (human answerable) or BAQ (bot answerable) meaning the question can be answered with a simple fact. |
|[The WestburyLab USENET corpus](https://aws.amazon.com/datasets/the-westburylab-usenet-corpus/) | Freely Downloadable | A corpus of anonymized postings from English language newsgroups between 2005 and 2010. Cleaned of emails and URLs. Documents are between 500 and 500,000 words long.
|[TIME Magazine Corpus of American English](https://corpus.byu.edu/time/)|Available Online|A corpus of American English as documented in issues of TIME Magazine. The corpus takes ~100 million words from 275,000 TIME Magazine articles.||
|[The Speech Accent Archive](http://accent.gmu.edu/index.php) | Available Online | A corpus composed of speech samples from many different languages and many different backgrounds. It contains voice recordings of speakers who are both native and non-native English speakers, a transcription of what they are saying, as well as a phonetic transcription of what they said.|
|[The Collins Corpus](https://collins.co.uk/page/The+Collins+Corpus?) | Available Online for Fee | An analytical database containing 4.5 billion words collected from websites, newspapers, magazines and books. |
|[Australian National Corpus](https://www.ausnc.org.au) | Available Online (Some corpora may have restricted access) |A corpus of Australian English text, transcriptions, audio, and audio-visual material|
|[Europarl Corpus](http://www.statmt.org/europarl/)| Freely Downloadable| Parallel corpus in 21 European languages extracted from the proceedings of the European Parliament 1996-2011|
|[El corpus del espa√±ol (BYU)](http://www.corpusdelespanol.org)|Free samples available, full data can be purchased|Divided into 2 parts, the corpus contains both historical and genre-based data (~100 million words) as well as dialectal variations collected from web resources (~2 billion words).|
|[International Computer Archive of Modern and Medieval English (ICAME)](http://clu.uni.no/icame/)|Online only for registered users of ICAME CD-ROM|ICAME is an international organization of linguists and information scientists working with English machine-readable texts. The aim of the organization is to collect and distribute information on English language material available for computer processing and on linguistic research completed or in progress on the material, to compile an archive of English text corpora in machine-readable form, and to make material available to research institutions.|

## Tools and software

| Name/link | Access | Summary |
| --------- | :-----------: | ------- |
|[AntConc Concordancer](http://www.laurenceanthony.net/software/antconc/) | free | A freeware corpus analysis toolkit for concordancing and text analysis |
|[Free CLAWS WWW tagger](http://ucrel.lancs.ac.uk/claws/trial.html) | free | A free web tagging service with access to the latest version of the tagger, CLAWS4. You can choose to have output in either the smaller C5 tagset or the larger C7 tagset. |
|[Praat](http://www.fon.hum.uva.nl/praat/download_win.html) | free | A free software for analyzing speech, specifically phonetics. |
|[Linger](http://tedlab.mit.edu/~dr/Linger/) | free | Software for computerized experiment design, data collection, analysis, and provides millisecond reaction time recording for reading times. Download comes with several sample experiment designs, such as self-paced reading, masked priming, speak-listen-answer, and lexical decision. Using non-English languages also possible. Also a verb that means to dwell in contemplation, thought, or enjoyment. |
|[Higgins Annotation Tool](http://www.speech.kth.se/hat/) | free | Software used to segment, annotate, and transcribe audio files as you listen to them. |
|[Spacy](https://spacy.io/) | free | Python package similar to NLTK for natural language processing, only faster, more versatile, and up to date! |
|[LanguageWare](https://www-01.ibm.com/marketing/iwm/tnd/demo.jsp?id=IBM+LanguageWare+Resource+Workbench) | Free Trial | Java libraries allowing for NLP functions including language identification, tokenization, and semantic analysis. |
|[JusText](http://corpus.tools/wiki/Justext)|Free|HTML Boilerplate remover. Automatically removes elements of HTML that are not text, such as links, images, HTML tags, headers, etc.|
|[SpiderLing](http://corpus.tools/wiki/SpiderLing) | Free | Software used to obtain text from webpages useful for the building of text corpora. The software combs over text and excludes things such as links and lists of products that aren't necessarily valuable to building text corpora. |
|[TreeTagger](http://www.ims.uni-stuttgart.de/forschung/ressourcen/werkzeuge/treetagger.html) in German | Free for research, education and evaluation. | Used for annotating text with part-of-speech and lemma information |
|[Unitok](http://corpus.tools/wiki/Unitok) | Free | Software that splits text into tokens. Recognizes abbreviations. Recognizes URLs, e-mail addresses, etc. Preserves XML tags. Adds glue tags between tokens not separated by space. |
|[Compleat Lexical Tutor (sic)](https://lextutor.ca)|Available Online| Free useful set of web-based analysis tools that include BNC, COCA, and BNC-COCA tools for analyzing frequency bands of words in texts, TTR ratios, and so on. It also contains concordancing programs in both French and English. This is one of the most useful tools on the web for ESL text profiling.|
|[Text Inspector](http://textinspector.com)|Available Online| Free lexcial profiling (D, TTR, T-units, etc.) for texts up to 500 words long. If longer texts are included, you can pay a modest subscription via credit card. Very handy for groups of shorter texts. The site makes good reference to the lexical diversity literature.|
|[TAPoR Collection](http://tapor.ca/home)|Varies|Not one resource, but many for studying textual information ranging from NLP and visualization to social media analysis and annotation.|
|[NLTK Natural Language Toolkit](http:://ntlk.org)|Free|"NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum." (nltk.org)|
